plot(x=theta, y=theta.prior, ylab="density", type="l")
sim.check<-rgamma(n=100000, shape=(mu.prior^2 / sigma.prior^2), rate=(mu.prior / sigma.prior^2))
mean(sim.check) # 10.20074
sd(sim.check) # 0.5013619
# Function to create vector of likelihood [y|theta]
like <- function(theta, y=y){
L.tot <- rep(NA, length(theta)) # initialize vector, same length as theta, i.e., we want the total likelihood for each value of theta
for (i in 1:length(theta)){
L.y <- dpois(x=y, lambda=theta[i]) # [yi|theta]; calculate likelihood for each data point given theta
L.tot[i]<-prod(L.y) # calculate TOTAL likelihood by taking the product across all L.y for the given theta
}
return(L.tot)
}
like.y<-like(theta,y)
plot(x=theta, y=like.y, ylab="[y|theta]", type="l")
joint <- function(theta){
prior(theta) * like(theta, y=y)
}
#Calculate Joint Distribution
numerator<-joint(theta)
plot(x=theta, y=numerator, ylab="Density", type="l") # y-axis are really small because these are products of very small numbers (especially totally likelihood numbers)
# Calculate [y] (i.e., normalization constant) by calculating area under the joint distribution
# Sum of rectangle areas; theta = widths of rectangles, numerator = heights of rectangles
marg.prob<-sum(theta.step*numerator)
# The posterior distribution: numerator / marg.prob
posterior <- numerator / marg.prob
plot(x=theta, y=posterior, ylab="Density", type="l")
# Re-scale the likelihood
like.scale1<-like.y/max(like.y)
like.scale2<-like.scale1*max(posterior)
plot(x=theta, y=posterior, ylab="density", type="n")
lines(x=theta, y=theta.prior, ylab="density", type="l", col="green") # prior green
lines(x=theta, y=like.scale2, ylab="[y|theta]", type="l", col="red") # likelihood red
lines(x=theta, y=posterior, type="l", col="blue") # posterior
set.seed(3) # assures that random number generator is the same each time
################################
# CHANGE sampsize to explore how SIZE OF DATASET can affect posterior distribution
sampsize<-50
y<-rpois(n=sampsize, lambda=6.4)
hist(y)
library(plyr) # NOTE: hist function not good for discreet data because it creates bin boundaries AT the discreet data points
plot(count(y), type="h")
mu.prior<-10.2
################################
# Change sigma.prior to explore how VARIANCE in prior will affect posterior distribution
sigma.prior<-0.5
theta.step<-0.01
theta<-seq(0,20,theta.step)
# Function to create vector of gamma probability densities (one for each value of theta)
prior <- function(theta, mu = mu.prior, sigma = sigma.prior){
alpha = mu^2 / sigma^2
beta = mu / sigma^2
dgamma(x=theta, shape=alpha, rate=beta)
}
theta.prior<-prior(theta=theta, mu=mu.prior, sigma=sigma.prior)
plot(x=theta, y=theta.prior, ylab="density", type="l")
sim.check<-rgamma(n=100000, shape=(mu.prior^2 / sigma.prior^2), rate=(mu.prior / sigma.prior^2))
mean(sim.check) # 10.20074
sd(sim.check) # 0.5013619
# Function to create vector of likelihood [y|theta]
like <- function(theta, y=y){
L.tot <- rep(NA, length(theta)) # initialize vector, same length as theta, i.e., we want the total likelihood for each value of theta
for (i in 1:length(theta)){
L.y <- dpois(x=y, lambda=theta[i]) # [yi|theta]; calculate likelihood for each data point given theta
L.tot[i]<-prod(L.y) # calculate TOTAL likelihood by taking the product across all L.y for the given theta
}
return(L.tot)
}
like.y<-like(theta,y)
plot(x=theta, y=like.y, ylab="[y|theta]", type="l")
joint <- function(theta){
prior(theta) * like(theta, y=y)
}
#Calculate Joint Distribution
numerator<-joint(theta)
plot(x=theta, y=numerator, ylab="Density", type="l") # y-axis are really small because these are products of very small numbers (especially totally likelihood numbers)
# Calculate [y] (i.e., normalization constant) by calculating area under the joint distribution
# Sum of rectangle areas; theta = widths of rectangles, numerator = heights of rectangles
marg.prob<-sum(theta.step*numerator)
# The posterior distribution: numerator / marg.prob
posterior <- numerator / marg.prob
plot(x=theta, y=posterior, ylab="Density", type="l")
# Re-scale the likelihood
like.scale1<-like.y/max(like.y)
like.scale2<-like.scale1*max(posterior)
plot(x=theta, y=posterior, ylab="density", type="n")
lines(x=theta, y=theta.prior, ylab="density", type="l", col="green") # prior green
lines(x=theta, y=like.scale2, ylab="[y|theta]", type="l", col="red") # likelihood red
lines(x=theta, y=posterior, type="l", col="blue") # posterior
set.seed(3) # assures that random number generator is the same each time
################################
# CHANGE sampsize to explore how SIZE OF DATASET can affect posterior distribution
sampsize<-500
y<-rpois(n=sampsize, lambda=6.4)
hist(y)
library(plyr) # NOTE: hist function not good for discreet data because it creates bin boundaries AT the discreet data points
plot(count(y), type="h")
mu.prior<-10.2
################################
# Change sigma.prior to explore how VARIANCE in prior will affect posterior distribution
sigma.prior<-0.5
theta.step<-0.01
theta<-seq(0,20,theta.step)
# Function to create vector of gamma probability densities (one for each value of theta)
prior <- function(theta, mu = mu.prior, sigma = sigma.prior){
alpha = mu^2 / sigma^2
beta = mu / sigma^2
dgamma(x=theta, shape=alpha, rate=beta)
}
theta.prior<-prior(theta=theta, mu=mu.prior, sigma=sigma.prior)
plot(x=theta, y=theta.prior, ylab="density", type="l")
sim.check<-rgamma(n=100000, shape=(mu.prior^2 / sigma.prior^2), rate=(mu.prior / sigma.prior^2))
mean(sim.check) # 10.20074
sd(sim.check) # 0.5013619
# Function to create vector of likelihood [y|theta]
like <- function(theta, y=y){
L.tot <- rep(NA, length(theta)) # initialize vector, same length as theta, i.e., we want the total likelihood for each value of theta
for (i in 1:length(theta)){
L.y <- dpois(x=y, lambda=theta[i]) # [yi|theta]; calculate likelihood for each data point given theta
L.tot[i]<-prod(L.y) # calculate TOTAL likelihood by taking the product across all L.y for the given theta
}
return(L.tot)
}
like.y<-like(theta,y)
plot(x=theta, y=like.y, ylab="[y|theta]", type="l")
joint <- function(theta){
prior(theta) * like(theta, y=y)
}
#Calculate Joint Distribution
numerator<-joint(theta)
plot(x=theta, y=numerator, ylab="Density", type="l") # y-axis are really small because these are products of very small numbers (especially totally likelihood numbers)
# Calculate [y] (i.e., normalization constant) by calculating area under the joint distribution
# Sum of rectangle areas; theta = widths of rectangles, numerator = heights of rectangles
marg.prob<-sum(theta.step*numerator)
# The posterior distribution: numerator / marg.prob
posterior <- numerator / marg.prob
plot(x=theta, y=posterior, ylab="Density", type="l")
# Re-scale the likelihood
like.scale1<-like.y/max(like.y)
like.scale2<-like.scale1*max(posterior)
plot(x=theta, y=posterior, ylab="density", type="n")
lines(x=theta, y=theta.prior, ylab="density", type="l", col="green") # prior green
lines(x=theta, y=like.scale2, ylab="[y|theta]", type="l", col="red") # likelihood red
lines(x=theta, y=posterior, type="l", col="blue") # posterior
dev.off()
sampsize<-500
y<-rpois(n=sampsize, lambda=6.4)
hist(y)
library(plyr) # NOTE: hist function not good for discreet data because it creates bin boundaries AT the discreet data points
plot(count(y), type="h")
mu.prior<-10.2
sigma.prior<-0.5
theta.step<-0.01
prior <- function(theta, mu = mu.prior, sigma = sigma.prior){
alpha = mu^2 / sigma^2
beta = mu / sigma^2
dgamma(x=theta, shape=alpha, rate=beta)
}
theta.prior<-prior(theta=theta, mu=mu.prior, sigma=sigma.prior)
plot(x=theta, y=theta.prior, ylab="density", type="l")
sim.check<-rgamma(n=100000, shape=(mu.prior^2 / sigma.prior^2), rate=(mu.prior / sigma.prior^2))
mean(sim.check) # 10.20074
sd(sim.check) # 0.5013619
like <- function(theta, y=y){
L.tot <- rep(NA, length(theta)) # initialize vector, same length as theta, i.e., we want the total likelihood for each value of theta
for (i in 1:length(theta)){
L.y <- dpois(x=y, lambda=theta[i]) # [yi|theta]; calculate likelihood for each data point given theta
L.tot[i]<-prod(L.y) # calculate TOTAL likelihood by taking the product across all L.y for the given theta
}
return(L.tot)
}
like.y<-like(theta,y)
plot(x=theta, y=like.y, ylab="[y|theta]", type="l")
rm(list=ls())
?dbeta
beta<-seq(0,1,0.001)
beta
phi<-seq(0,1,0.001)
rm(bewta)
rm(beta)
phi<-seq(0,1,0.001)
prior<-dbeta(x=phi, shape1=1, shape2=1)
plot(x=phi, y=prior, type="l")
posterior<-dbeta(x=phi, shape1=4, shape2=8)
plot(x=phi, y=posterior, type="l")
?pbeta
pbeta(q=c(0.5,1), shape1=4, shape2=8)
pbeta(q=0.5, shape1=4, shape2=8)
1-pbeta(q=0.5, shape1=4, shape2=8)
?qbeta
qbeta(p=c(0.025,0.975), shape1=4, shape2=8)
y<-rep(0,10)
y[1:3]<-1
alpha.prior<-1
beta.prior<-1
prior<-dbeta(x=phi, shape1=alpha.prior, shape2=beta.prior)
plot(x=phi, y=prior, type="l")
alpha.posterior<-sum(y)+alpha.prior
beta.posterior<-n-sum(y)+beta.prior
n<-10 # No. of trials
beta.posterior<-n-sum(y)+beta.prior
posterior<-dbeta(x=phi, shape1=alpha.posterior, shape2=beta.posterior)
plot(x=phi, y=posterior, type="l")
1-pbeta(q=0.5, shape1=4, shape2=8)
qbeta(p=c(0.025,0.975), shape1=4, shape2=8)
library(SESYNCBayes)
head(ClimateVote)
head(ClimateVote)
dim(ClimateVote)
mu<-mean(posterior)
sd(posterior)
mu<-sum(phi*posterior)
posterior<-dbeta(x=phi, shape1=alpha.posterior, shape2=beta.posterior)
plot(x=phi, y=posterior, type="l")
dat<-rep(0,n) # No. of successes
dat[1:3]<-1
y<-sum(dat)
y<-sum(ClimateVote[,2])
y
alpha.prior<-4 # Use previous posterior as new prior
beta.prior<-8
prior<-dbeta(x=phi, shape1=alpha.prior, shape2=beta.prior)
plot(phi, prior, type="l")
alpha.posterior<-y+alpha.prior
beta.posterior<-n-y+beta.prior
n<-100
beta.posterior<-n-y+beta.prior
posterior<-dbeta(x=phi, shape1=alpha.posterior, shape2=beta.posterior)
plot(x=phi, y=posterior, type="l")
1-pbeta(q=0.5, shape1=4, shape2=8)
qbeta(p=c(0.025,0.975), shape1=alpha.posterior, shape2=beta.posterior)
1-pbeta(q=0.5, shape1=alpha.posterior, shape2=beta.posterior)
?dpois
lambda<-seq(0,20,0.01)
?dgamma
prior<-dgamma(lambda, shape=alpha.prior, rate=beta.prior)
plot(lambda, prior, type="l")
alpha.prior<-mu^2/sigma^2
lambda<-seq(0,20,0.01)
mu<-3
sigma<-1.5
alpha.prior<-mu^2/sigma^2
beta.prior<-mu/sigma^2
prior<-dgamma(lambda, shape=alpha.prior, rate=beta.prior)
plot(lambda, prior, type="l")
plot(lambda, prior, type="l", ylab="Density", main="Prior")
y<-sum(dat)
n <- length(y)
alpha.post<-alpha.prior+sum(y)
beta.post<-beta.prior+n
plot(lambda, posterior, type="l", ylab="Density", main="Posterior")
alpha.post<-alpha.prior+sum(y)
beta.post<-beta.prior+n
posterior<-dgamma(lambda, shape=alpha.post, rate=beta.post)
plot(lambda, posterior, type="l", ylab="Density", main="Posterior")
beta.post<-beta.prior+n
alpha.prior<-mu^2/sigma^2
beta.prior<-mu/sigma^2
alpha.post<-alpha.prior+sum(y)
beta.post<-beta.prior+n
posterior<-dgamma(lambda, shape=alpha.post, rate=beta.post)
plot(lambda, posterior, type="l", ylab="Density", main="Posterior")
?dbeta
dbeta(phi, 0, 0)
rm(list=ls())
set.seed(1)
library(actuar)
install.packages("actuar")
library(actuar)
?rnorm
y<-rnorm(n=100, mean=100, sd=5)
set.seed(1)
theta=100
var.sigmasq=25
library(actuar)
y<-rnorm(n=1, mean=theta, sd=sqrt(var.sigmasq))
samps=100
y<-rnorm(n=100, mean=theta, sd=sqrt(var.sigmasq))
sqrt(var.sigmasq)
draw_mean = function(mu_0, sigma.sq_0, varsigma.sq, y) {
mu_1 = ((mu_0/sigma.sq_0 + sum(y)/varsigma.sq))/(1/sigma.sq_0 + length(y)/varsigma.sq)
sigma.sq_1 = 1/(1/sigma.sq_0 + length(y)/varsigma.sq)
z = rnorm(1, mu_1, sqrt(sigma.sq_1))
param = list(z = z, mu_1 = mu_1, sigma.sq_1 = sigma.sq_1)
return(param)
}
draw_var = function(alpha_0, beta_0, theta, y) {
alpha_1 = alpha_0 + length(y)/2
beta_1 = beta_0 + sum((y - theta)^2)/2
z = rinvgamma(1, alpha_1, scale = beta_1)
param = list(z = z, alpha_1 = alpha_1, beta_1 = beta_1)
return(param)
}
iter = 10000
chains = 3
var.post = matrix(nrow = iter, ncol = chains)
mean.post = matrix(nrow = iter, ncol = chains)
iter = 10000
chains = 3
var.post = matrix(nrow = chains, ncol = iter)
mean.post = matrix(nrow = chains, ncol = iter)
var.post[,1:3]
var.post[,1]
var.post[,1]<-c(1, 10, 100)
mean.post[,1]<-c(10, 100, 1000)
var.post[,1:3]
mean.post[,1:3]
var.post[,1]<-c(0.1, 1, 10)
draw_mean = function(mu_0, sigma.sq_0, varsigma.sq, y) {
mu_1 = ((mu_0/sigma.sq_0 + sum(y)/varsigma.sq))/(1/sigma.sq_0 + length(y)/varsigma.sq)
sigma.sq_1 = 1/(1/sigma.sq_0 + length(y)/varsigma.sq)
z = rnorm(1, mu_1, sqrt(sigma.sq_1))
param = list(z = z, mu_1 = mu_1, sigma.sq_1 = sigma.sq_1)
return(param)
}
draw_var = function(alpha_0, beta_0, theta, y) {
alpha_1 = alpha_0 + length(y)/2
beta_1 = beta_0 + sum((y - theta)^2)/2
z = rinvgamma(1, alpha_1, scale = beta_1)
param = list(z = z, alpha_1 = alpha_1, beta_1 = beta_1)
return(param)
}
iter = 10000
chains = 3
var.post = matrix(nrow = chains, ncol = iter)
mean.post = matrix(nrow = chains, ncol = iter)
var.post[,1]<-c(0.1, 1, 10)
mean.post[,1]<-c(1, 10, 100)
t=2
head(mean.post)
mean.post[,1:3]
for (j in 1:chains) {
mean.post[j, t] = draw_mean(mu_0 = 0, sigma.sq_0 = 1000, varsigma.sq = var.post[j,t - 1], y = y)$z
var.post[j, t] = draw_var(alpha_0 = 0.001, beta_0 = 0.001, theta = mean.post[j, t], y = y)$z
}
mean.post[,1:3]
var.post[,1:3]
for (t in 2:iter) {
for (j in 1:chains) {
mean.post[j, t] = draw_mean(mu_0 = 0, sigma.sq_0 = 1000, varsigma.sq = var.post[j,t - 1], y = y)$z
var.post[j, t] = draw_var(alpha_0 = 0.001, beta_0 = 0.001, theta = mean.post[j, t], y = y)$z
}
}
dim(var.post)
length(var.post)
var.samps<-var.post[,burn.in:dim(var.post)[2]]
burn.in<-1000
var.samps<-var.post[,burn.in:dim(var.post)[2]]
ncol(var.samps)
ncol(var.post)
samps.start<-1001
var.samps<-var.post[,samps.start:dim(var.post)[2]]
ncol(var.samps)
mean.samps<-mean.post[,samps.start:dim(mean.post)[2]]
ncol(mean.samps)
str(var.samps)
plot(y=mean.samps[1,], type="n")
plot(y=mean.samps[1,], x=1:length(mean.samps[1,], type="n")
length(mean.samps[1,])
plot(y=mean.samps[1,], x=1:length(mean.samps[1,]), type="n")
plot(y=mean.samps[1,], x=1:length(mean.samps[1,]), type="n", y="mean", x="iteration")
plot(y=mean.samps[1,], x=1:length(mean.samps[1,]), type="n", ylab="mean", xlab="iteration")
lines(y=mean.samps[1,], type="l")
lines(y=mean.samps[1,], x=1:length(mean.samps[1,]), type="l")
plot(var.samps)
var.samps[,1:3]
plot(y=mean.samps[1,], x=1:length(mean.samps[1,]), type="n", ylab=expression(theta), xlab="iteration")
lines(y=mean.samps[1,], x=1:length(mean.samps[1,]), type="l", col="green")
lines(y=mean.samps[2,], x=1:length(mean.samps[1,]), type="l", col="red")
lines(y=mean.samps[3,], x=1:length(mean.samps[1,]), type="l", col="yellow")
hist(mean.samps)
length(mean.samps)
?hist
hist(mean.samps, freq=FALSE)
hist(mean.samps, freq=FALSE, main=expression(theta))
hist(mean.samps, freq=FALSE, main=expression(theta), xlab="MCMC Samples")
lines(density(mean.samps), col = "red", lwd = 3)
abline(v = theta, lty = "dashed", col = "blue", lwd = 4)
plot(y=var.samps[1,], x=1:length(var.samps[1,]), type="n", ylab=expression(varsigma^2), xlab="iteration")
lines(y=var.samps[1,], x=1:length(var.samps[1,]), type="l", col="green")
lines(y=var.samps[2,], x=1:length(var.samps[1,]), type="l", col="red")
lines(y=var.samps[3,], x=1:length(var.samps[1,]), type="l", col="yellow")
hist(var.samps, freq=FALSE, main=expression(varsigma^2), xlab="MCMC Samples")
lines(density(var.samps), col = "red", lwd = 3)
abline(v = var.sigmasq, lty = "dashed", col = "blue", lwd = 4)
plot(y=mean.samps[1,], x=1:length(mean.samps[1,]), type="n", ylab=expression(theta), xlab="iteration")
lines(y=mean.samps[1,], x=1:length(mean.samps[1,]), type="l", col="blue")
lines(y=mean.samps[2,], x=1:length(mean.samps[1,]), type="l", col="red")
lines(y=mean.samps[3,], x=1:length(mean.samps[1,]), type="l", col="yellow")
plot(y=var.samps[1,], x=1:length(var.samps[1,]), type="n", ylab=expression(varsigma^2), xlab="iteration")
lines(y=var.samps[1,], x=1:length(var.samps[1,]), type="l", col="blue")
lines(y=var.samps[2,], x=1:length(var.samps[1,]), type="l", col="red")
lines(y=var.samps[3,], x=1:length(var.samps[1,]), type="l", col="yellow")
hist(var.samps, freq=FALSE, main=expression(varsigma^2), xlab="MCMC Samples")
lines(density(var.samps), col = "red", lwd = 3)
abline(v = var.sigmasq, lty = "dashed", col = "blue", lwd = 4)
hist(var.samps, freq=FALSE, main=expression(varsigma^2), xlab="MCMC Samples")
lines(density(var.samps), col = "red", lwd = 3)
abline(v = var.sigmasq, lty = "dashed", col = "blue", lwd = 2)
hist(var.samps, freq=FALSE, main=expression(varsigma^2), xlab="MCMC Samples")
lines(density(var.samps), col = "red", lwd = 2)
abline(v = var.sigmasq, lty = "dashed", col = "blue", lwd = 2)
mean(mean.samps)
sd(mean.samps)
mean(var.samps)
sd(var.samps)
dnorm(1, mean=12, sd=1.5)
?dnorm
dnorm(10, mean=12, sd=1.5)
dnorm(12, 10, 1.5)
?dgamma
mu=12
sig=1.5
alpha=mu^2/sig^2
beta=mu/sig^2
pars=list(alpha, beta)
pars
names(pars)
str(pars)
names(pars[1])<-"alpha"
names(pars[2])<-"beta"
pars
names(pars[[1]])<-"alpha"
pars
names(pars[[2]])<-"beta"
pars$alpha
pars[[alpha]]
pars[alpha]
names(pars)
names(pars[[2]])<-"beta"
pars
gamma_moment<-function(mu, sig){
alpha=mu^2/sig^2
beta=mu/sig^2
pars=list(alpha, beta)
names(pars[[1]])<-"alpha"
names(pars[[2]])<-"beta"
return(pars)
}
gamma_moment(mu=12, sig=1.5)
dgamma(x=10, shape=64, beta=5.33)
dgamma(x=10, shape=64, rate=5.33)
gamma_moment(mu=12, sig=1.5)
gamma_moment(mu=10, sig=1.5)
dgamma(x=12, shape=44.44, rate=4.44)
?nls
# Deterministic model:
g = function(alpha, gamma, c, L){
mu = alpha * (L - c) / (alpha/gamma + (L - c))
return(mu)
}
?rbinom
rbinom(1, 3, 0)
library(rjags)
library(SESYNCBayes)
bird.df <- RichnessBirds
idx.outlier=(1:51)[(bird.df$species==min(bird.df$species) | bird.df$area==max(bird.df$area))]
bird.sm.df=bird.df[-idx.outlier,]
head(bird.df)
(bird.df$species==min(bird.df$species)
bird.df$species==min(bird.df$species)
bird.df$area==max(bird.df$area)
idx.outlier
dim(bird.df)
dim(bird.sm.df)
head(bird.sm.df)
X = model.matrix(~as.numeric(scale(area)), data = bird.sm.df) # model 2
head(X)
dim(bird.sm.df)
nrows(bird.sm.df)
ncols(bird.sm.df)
nrow(bird.sm.df)
nobs = nrow(bird.sm.df)
X = rep(1, nobs) # model 1
X
bird.df
bird.sm.df
nobs = nrow(bird.sm.df)
#Use these to run differnt models, ucommenting one at a time.
X = rep(1, nobs) # model 1
#X = model.matrix(~as.numeric(scale(area)), data = bird.sm.df) # model 2
#X = model.matrix(~as.numeric(scale(temp)), data = bird.sm.df) # model 3
#X = model.matrix(~as.numeric(scale(precip)), data = bird.sm.df) # model 4
#X = model.matrix(~as.numeric(scale(area)) + as.numeric(scale(temp)), data = bird.sm.df) # model 5
y = bird.sm.df$species
as.matrix(X)
nbeta = ncol(X)
ncol(X)
X = as.matrix(X)
nbeta = ncol(X)
nbeta
rm(list=ls())
rm(list=ls())
dataset<-"slope_slope"
citation()
?rjags
library(rjags)
citations()
citation()
install.packages("regal")
library(rgdal)
setwd("~/Analyses/Target10HI/input/shapefiles_Sectors")
sectorShape<-readOGR(".","MHI_Sectors")
sectorShape<-spTransform(sectorShape, CRS("+proj=longlat +datum=WGS84"))
library(ggmap)
mapCenter<-geocode("21.138847, -157.233290") # LAT/LONG of western Molokai taken from GoogleMaps
hawaii<-get_map(c(lon=mapCenter$lon, lat=mapCenter$lat), zoom=12, maptype="terrain", source="google")
hawaiiMap<-ggmap(hawaii)
hawaiiMap
library(ggmap)
hawaiiMap<-ggmap(hawaii)
install.packages("ggmap")
