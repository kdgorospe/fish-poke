mcmc.yrecovery.sector.mean<-aggregate(as.matrix(z3a.yrecovery.tf[,2:ncol(z3a.yrecovery.tf)]) ~ z3a.yrecovery.tf$SC, data=z3a.yrecovery.tf, FUN=mean)
# Each row is now a mcmc of sector-level y.reps: use each row to generate sector-level means and quantiles
yrecovery.sector.quantiles<-apply(X=mcmc.yrecovery.sector.mean[,-1], MARGIN=1, FUN=quantile, probs=quantilesofinterest)
colnames(yrecovery.sector.quantiles)<-mcmc.yrecovery.sector.mean[,1]
yrecovery.sector.quantiles<-t(yrecovery.sector.quantiles)
yrecovery.sector.quantiles<-as.data.frame(yrecovery.sector.quantiles)
allrecovery.quantiles<-as.data.frame(cbind(allrecovery.quantiles, yrecovery.sector.quantiles))
}
## AVERAGE ACROSS THE THREE CHAINS
quantilenames<-c("17%", "25%", "50%", "75%", "83%")
firstquantile<-quantilenames[1]
#firstquant.cols<-grep(firstquantile, names(allrecovery.quantiles))
firstquant.cols<-which(names(allrecovery.quantiles)==firstquantile)
allrecovery.firstquant<-as.data.frame(apply(allrecovery.quantiles[,firstquant.cols], MARGIN=1, FUN=mean))
names(allrecovery.firstquant)<-firstquantile
df.recovery.quantiles<-allrecovery.firstquant
quantilelist<-quantilenames[-1]
for(i in 1:length(quantilelist)){
quant<-quantilelist[i]
#quant.cols<-grep(quant, names(allrecovery.quantiles))
quant.cols<-which(names(allrecovery.quantiles)==quant)
allrecovery.quant<-as.data.frame(apply(allrecovery.quantiles[,quant.cols], MARGIN=1, FUN=mean))
names(allrecovery.quant)[1]<-quantilelist[i]
df.recovery.quantiles<-cbind(allrecovery.quant, df.recovery.quantiles)
}
names(df.recovery.quantiles)<-paste("recovery_", names(df.recovery.quantiles), sep="")
# PLOT BAR GRAPHS of BIOMASS RECOVERY POTENTIAL
row.names(df.recovery.quantiles)<-sects
dat<-cbind(row.names(df.recovery.quantiles), df.recovery.quantiles)
names(dat)[1]<-"SC"
# EXPORT dat for mapping later
write.csv(dat, file = "mappingData_recoveryEstimates.csv", quote=FALSE, row.names=FALSE)
## REORDER AXIS from highest to lowest natural (i.e., minimal impact) fish biomass levels
sc.order<-dat$SC[order(dat$'recovery_50%', decreasing=FALSE)]
sc.order
sc.index<-order(dat$'recovery_50%', decreasing=FALSE)
# set order from lowest to highest (i.e., increasing bioamss levels) - later, coords_flip() function corrects this to decreasing biomass levels
# LEVELS should be sorted based on sc.index - GRAPHING order is based on order of levels
dat$SC<-factor(dat$SC, levels(dat$SC)[sc.index])
levels(dat$SC)
names(dat)[c(2,6)]<-c("UpperRP", "LowerRP")
names(dat)[4]<-"MidRP"
p<-ggplot(data=dat, aes(x=SC, y=MidRP)) +
geom_errorbar(aes(ymin=LowerRP, ymax=UpperRP), colour="slateblue", size=1.2, width=0.5) +
geom_point(aes(x=SC, y=MidRP), size=2, colour="slateblue") +
labs(y=expression(paste("Biomass (g",m^{-2}, ") Recovery Potential")), x="") +
theme_light()+
theme(text = element_text(size=18), axis.text.x=element_text(vjust=0.5, colour="black", size=18),
legend.position="none") +
coord_flip()
setwd("~/Analyses/RESULTS/fish-stock")
pdf(file="sectorLevelRecoveryPotential_independentChains_avgQuantiles.pdf")
print(p)
dev.off()
################################################################################################
################################################################################################
#### CALCULATE SECTOR-LEVEL AVERAGES OF percent recovery (i.e., y.pctrecov) ####################
################################################################################################
################################################################################################
z3a.ypctrecov<-z3a.burnin[,y.pctrecov.cols]
### AS ABOVE, calculate quantiles separately for EACH chain, and then average the quantiles
## ADJUST QUANTILES OF INTEREST and QNORM for y.mean (i.e. 95% vs 80% Confidence Intervals)
quantilesofinterest=c(.17, .25, .5, .75, .83)
allpctrecovery.quantiles<-as.data.frame(NA)
for(i in 1:length(z3a.ypctrecov)){
z3a.ypctrecov.df<-as.data.frame(z3a.ypctrecov[[i]])
z3a.ypctrecov.tf<-t(z3a.ypctrecov.df)
z3a.ypctrecov.tf<-as.data.frame(z3a.ypctrecov.tf)
z3a.ypctrecov.tf<-cbind(dat.final$SEC_NAME, z3a.ypctrecov.tf)
names(z3a.ypctrecov.tf)[1]<-"SC"
## THEN, use "SC" to calculate mean biomass aggregated at the sector level at EACH STEP
mcmc.ypctrecov.sector.mean<-aggregate(as.matrix(z3a.ypctrecov.tf[,2:ncol(z3a.ypctrecov.tf)]) ~ z3a.ypctrecov.tf$SC, data=z3a.ypctrecov.tf, FUN=mean)
# Each row is now a mcmc of sector-level y.reps: use each row to generate sector-level means and quantiles
ypctrecov.sector.quantiles<-apply(X=mcmc.ypctrecov.sector.mean[,-1], MARGIN=1, FUN=quantile, probs=quantilesofinterest)
colnames(ypctrecov.sector.quantiles)<-mcmc.ypctrecov.sector.mean[,1]
ypctrecov.sector.quantiles<-t(ypctrecov.sector.quantiles)
ypctrecov.sector.quantiles<-as.data.frame(ypctrecov.sector.quantiles)
allpctrecovery.quantiles<-as.data.frame(cbind(allpctrecovery.quantiles, ypctrecov.sector.quantiles))
}
## AVERAGE ACROSS THE THREE CHAINS
quantilenames<-c("17%", "25%", "50%", "75%", "83%")
firstquantile<-quantilenames[1]
#firstquant.cols<-grep(firstquantile, names(allrecovery.quantiles))
firstquant.cols<-which(names(allpctrecovery.quantiles)==firstquantile)
allpctrecovery.firstquant<-as.data.frame(apply(allpctrecovery.quantiles[,firstquant.cols], MARGIN=1, FUN=mean))
names(allpctrecovery.firstquant)<-firstquantile
df.pctrecovery.quantiles<-allpctrecovery.firstquant
quantilelist<-quantilenames[-1]
for(i in 1:length(quantilelist)){
quant<-quantilelist[i]
#quant.cols<-grep(quant, names(allrecovery.quantiles))
quant.cols<-which(names(allpctrecovery.quantiles)==quant)
allpctrecovery.quant<-as.data.frame(apply(allpctrecovery.quantiles[,quant.cols], MARGIN=1, FUN=mean))
names(allpctrecovery.quant)[1]<-quantilelist[i]
df.pctrecovery.quantiles<-cbind(allpctrecovery.quant, df.pctrecovery.quantiles)
}
names(df.pctrecovery.quantiles)<-paste("pctrecovery_", names(df.pctrecovery.quantiles), sep="")
# PLOT BAR GRAPHS of PERCENT RECOVERY POTENTIAL
row.names(df.pctrecovery.quantiles)<-sects
dat<-cbind(row.names(df.pctrecovery.quantiles), df.pctrecovery.quantiles)
names(dat)[1]<-"SC"
names(dat)[2]<-"Upper"
names(dat)[6]<-"Lower"
names(dat)[4]<-"Mid"
# EXPORT dat for mapping later
write.csv(dat, file = "mappingData_percentRecoveryEstimates.csv", quote=FALSE, row.names=FALSE)
### PLOT  UNORDERED GRAPH
p=ggplot(data=dat, aes(x=SC, y=Mid)) +
geom_point(aes(x=SC, y=Mid))+
labs(x="Sector", y="percent recovery") +
theme(text = element_text(size=22),
axis.text.x=element_text(angle=90, hjust=0, vjust=0.5, colour="black", size=10),
legend.position="bottom", legend.title=element_blank()) +
geom_errorbar(aes(ymin=dat$Lower, ymax=dat$Upper))
setwd("~/Analyses/RESULTS/fish-stock")
pdf(file="sectorLevelPercentRecoveryPotential-unordered_independentChains_avgQuantiles.pdf")
print(p)
dev.off()
## REORDER AXIS from highest to lowest natural (i.e., minimal impact) fish biomass levels
sc.order<-dat$SC[order(dat$Mid, decreasing=FALSE)]
sc.order
sc.index<-order(dat$Mid, decreasing=FALSE)
# set order from lowest to highest (i.e., increasing bioamss levels) - later, coords_flip() function corrects this to decreasing biomass levels
# LEVELS should be sorted based on sc.index - GRAPHING order is based on order of levels
dat$SC<-factor(dat$SC, levels(dat$SC)[sc.index])
levels(dat$SC)
names(dat)[c(2,6)]<-c("UpperPercent", "LowerPercent")
names(dat)[4]<-"MidPercent"
p<-ggplot(data=dat, aes(x=SC, y=MidPercent)) +
geom_errorbar(aes(ymin=LowerPercent, ymax=UpperPercent), colour="forestgreen", size=1.2, width=0.5) +
geom_point(aes(x=SC, y=MidPercent), size=2, colour="forestgreen") +
labs(y=expression(paste("Biomass (g",m^{-2}, ") Percent Recovery Potential")), x="") +
theme_light()+
theme(text = element_text(size=18), axis.text.x=element_text(vjust=0.5, colour="black", size=18),
legend.position="none") +
coord_flip()
setwd("~/Analyses/RESULTS/fish-stock")
pdf(file="sectorLevelPercentRecoveryPotential_independentChains_avgQuantiles.pdf")
print(p)
dev.off()
#SAVE DATA
#rm(z3a.pars, z3a.sim)
save.image(file="_bayesianSavedWorkspace_forReDoingOutputs.RData")
fish
rm(list=ls())
library(reshape) # needed for melt()
library(rjags)
library(xtable)
library(coda)
library(gdata)    # needed for drop.levels()
library(car)      # needed for Variance Inflation Factor calculation
library(ggplot2)
library(corrplot)
##### CHANGE RESPONSE VARIABLE AS NEEDED: "PRIMARY" VS "INSTTotFishMinusSJRTB"
setwd("~/Analyses/fish-stock")
load("~/Analyses/fish-stock/input/TMPwsd_MHI_AllHerbivoresThru2016.RData") # by CONSUMER GROUPS
#load("~/Analyses/fish-stock/input/TMPwsd_REAthru2017-SpeciesLevel.RData") # by SPECIES
mhi<-wsd
#### GIVE "mhi" fish data to TOMOKO join with OCEANOGRAPHY data in ArcMAP
### FILES below are result of joining dat above with Jamie's latest oceanography data by averaging three nearest neighbors to fish sites
### For now, using Jamie's latest updated oceanography metrics (summarized thru 31 Dec 2014 - except waves which is Dec 2013)
chl.dat<-read.csv("~/Analyses/fish-stock/input/oceanInput/ChlA_fishDat_Join.csv")
irr.dat<-read.csv("~/Analyses/fish-stock/input/oceanInput/PAR_fishDat_Join.csv")
sst.dat<-read.csv("~/Analyses/fish-stock/input/oceanInput/SST_fishDat_Join.csv")
wav.dat<-read.csv("~/Analyses/fish-stock/input/oceanInput/Wave_fishDat_Join.csv")
chl.dat<-subset(chl.dat, select=-POINT_FREQUENCY)
irr.dat<-subset(irr.dat, select=-POINT_FREQUENCY)
sst.dat<-subset(sst.dat, select=-POINT_FREQUENCY)
wav.dat<-subset(wav.dat, select=-POINT_FREQUENCY)
# Merge all ocean dat together
ocean.common<-names(chl.dat)[1:75] #### NOTE: COLUMN NAMES ARE HARD-CODED; NEED TO REVISIT THIS IF NEW DATAFILES ARE EVER USED
ocean.dat<-merge(chl.dat, irr.dat, by=ocean.common, all=TRUE)
ocean.dat<-merge(ocean.dat, sst.dat, by=ocean.common, all=TRUE)
ocean.dat<-merge(ocean.dat, wav.dat, by=ocean.common, all=TRUE)
### All data including data from post-bleaching years
table(mhi$OBS_YEAR, mhi$REGION)
#MHI NWHI PRIAs SAMOA S.MARIAN N.MARIAN
#2007   0  117     0     0        0        0
#2008   0    0    96   112        0        0
#2009   0  181    29     0       82       95
#2010 184  118   179   241        0        0
#2011   0  141    30     0      219      135
#2012 163   91   231   223        0        0
#2013 287    0     0     0        0        0
#2014   0   89    45     0      210      148
#2015 294   96   291   338        0        0
#2016 256  182    30   185        0        0
#2017   0    0    81     0      172      159
table(ocean.dat$OBS_YEAR, ocean.dat$REGION)
#MHI
#2012 163
#2013 287
#2015 294
#2016 256
# i.e. REA data (mhi) and oceanography data (ocean.dat) have the same # of sites - merge should be perfect
### MERGE with fish data - simplify the merge by removing most common columns
ocean.dat<-subset(ocean.dat, select=-c(LATITUDE, LONGITUDE, DATE_, ANALYSIS_SEC, ANALYSIS_STRATA, ANALYSIS_YEAR, SEC_NAME,
METHOD, OBS_YEAR, REGION, REGION_NAME, ISLAND, REEF_ZONE, DEPTH_BIN, HABITAT_CODE,
DEPTH, HARD_CORAL, MA, CCA, SAND, OTHER_BENTHIC, MEAN_SH, SD_SH_DIFF, MAX_HEIGHT,
VISIBILITY, nCounts, nReps))
### All data including post-bleaching 2016 data
common<-c("SITEVISITID", "SITE")
alldat<-merge(mhi, ocean.dat, by=common)
### Only the study data - 2012 thru 2015
study.dat<-subset(alldat, OBS_YEAR<2016 & OBS_YEAR>2011)
# Join with Humans and Site Data
siteDat<-read.csv("~/Analyses/fish-stock/input/SITE MASTER2016.csv")
#W Again - simplify the merge by removing most common columns
#Slight differences in the object class for "DATE_" and number of decimal numbers for "LAT" and "LONG"
sub.dat<-subset(study.dat, select=-c(DATE_, LATITUDE, LONGITUDE, ANALYSIS_YEAR, SEC_NAME))
#common<-names(siteDat)[names(siteDat) %in% names(study.dat)]
common<-c("SITE", "SITEVISITID", "REGION", "ISLAND", "REEF_ZONE", "OBS_YEAR", "DEPTH_BIN")
dat<-merge(sub.dat, siteDat, by=common)
### MERGE with benthic image analysis data (CPCe and CNET)
# Read in benthic image analysis (CPCe and CNET)
benthic.cnet<-read.csv(file="~/Analyses/fish-stock/input/Kelvin MHI BenthicImageAnalysis_CNET.csv", header=TRUE)
benthic.cpce<-read.csv(file="~/Analyses/fish-stock/input/Kelvin MHI BenthicImageAnalysis_CPCE.csv", header=TRUE)
## Aggregate morphology columns in CPCE data
# Encrusting corals:
enc.cols<-benthic.cpce[,grep("_ENC", names(benthic.cpce))]
# Sum and create new column that is identical to the column in benthic.cnet
benthic.cpce$CORAL_Encrusting.hard.coral<-apply(enc.cols, MARGIN=1, FUN=sum)
# Massive corals:
mass.cols<-benthic.cpce[,grep("_MASS", names(benthic.cpce))]
# Sum and create new column that is identical to the column in benthic.cnet
benthic.cpce$CORAL_Massive.hard.coral<-apply(mass.cols, MARGIN=1, FUN=sum)
# Branching corals:
bran.cols<-benthic.cpce[,grep("_BR", names(benthic.cpce))]
# Sum and create new column that is identical to the column in benthic.cnet
benthic.cpce$CORAL_Branching.hard.coral<-apply(bran.cols, MARGIN=1, FUN=sum)
common.cats<-names(benthic.cnet)[names(benthic.cnet) %in% names(benthic.cpce)]
benthic.cnet.common<-subset(x=benthic.cnet, select=common.cats)
benthic.cpce.common<-subset(x=benthic.cpce, select=common.cats)
benthic<-rbind(benthic.cnet.common, benthic.cpce.common)
#Again, when merging, don't merge by date, latitude, or longitude.
common2<-names(benthic)[names(benthic) %in% names(dat)]
common<-common[!(common %in% c("DATE_", "LATITUDE", "LONGITUDE"))]
benthic<-subset(benthic, select=-c(DATE_, LATITUDE, LONGITUDE))
common2<-c("SITE", "REGION", "ISLAND", "REEF_ZONE", "OBS_YEAR", "DEPTH_BIN")
dat<-merge(dat, benthic, by=common2)
write.csv(dat, file="~/Analyses/fish-stock/RESULTS/allDat_2012-2015_JOIN.csv", quote=FALSE)
### DAT drops from 744 rows to 730 rows (which sites are missing??)
# Sites that drop out:
#mhi$SITE[!mhi$SITE %in% dat$SITE]
#[1] LAN-00202 MAI-00472 MAI-00470 MOL-00482 KAU-00253 OAH-00432 OAH-00485
#[8] OAH-00444 OAH-00421 OAH-00428 OAH-00404 OAH-00385 OAH-00391 NII-01338
# ALL HAVE MISSING BENTHIC IMAGE ANALYSIS DATA (COULD POTENTIALLY BRING IN VISUAL ESTIMATED DATA, BUT THIS WOULD BE INCONSISTENT - HAVE ENOUGH SITES, OK WITH DROPPING THESE)
## ADD HABITAT CATEGORY ID VARIABLES
# ADD ID VARIABLE FOR REEF vs NONREEF
#reef.hab<-(dat$HABITAT_CODE=="AGR" | dat$HABITAT_CODE=="APR" | dat$HABITAT_CODE=="APS")
reef.hab<-(dat$HABITAT_CODE=="AGR")
dat$REEF<-as.numeric(reef.hab)
# ADD ID VARIABLE FOR PAVEMENT vs NON-PAVEMENT
#pave.hab<-(dat$HABITAT_CODE=="PAV" | dat$HABITAT_CODE=="PPR" | dat$HABITAT_CODE=="PSC" | dat$HABITAT_CODE=="SCR" | dat$HABITAT_CODE=="RRB")
pave.hab<-(dat$HABITAT_CODE=="PAV")
dat$PAV<-as.numeric(pave.hab)
# ADD ID VARIABLE FOR ROB vs NONROB
rob.hab<-dat$HABITAT_CODE=="ROB"
dat$ROB<-as.numeric(rob.hab)
# ADD ID VARIABLE FOR APR vs NONAPR
apr.hab<-dat$HABITAT_CODE=="APR"
dat$APR<-as.numeric(apr.hab)
# ADD ID VARIABLE FOR APS vs NONAPS
aps.hab<-dat$HABITAT_CODE=="APS"
dat$APS<-as.numeric(aps.hab)
# ADD ID VARIABLE FOR MIX vs NONMIX
mix.hab<-dat$HABITAT_CODE=="MIX"
dat$MIX<-as.numeric(mix.hab)
# ADD ID VARIABLE FOR PPR vs PPR
ppr.hab<-dat$HABITAT_CODE=="PPR"
dat$PPR<-as.numeric(ppr.hab)
# ADD ID VARIABLE FOR PSC vs NONPSC
psc.hab<-dat$HABITAT_CODE=="PSC"
dat$PSC<-as.numeric(psc.hab)
# ADD ID VARIABLE FOR RRB vs NONRRB
rrb.hab<-dat$HABITAT_CODE=="RRB"
dat$RRB<-as.numeric(rrb.hab)
# ADD ID VARIABLE FOR SAG vs NONSAG
sag.hab<-dat$HABITAT_CODE=="SAG"
dat$SAG<-as.numeric(sag.hab)
# ADD ID VARIABLE FOR SCR vs NONSCR
scr.hab<-dat$HABITAT_CODE=="SCR"
dat$SCR<-as.numeric(scr.hab)
# WILL HAVE TO DROP LEVELS FOR OTHER hierarchical levels (e.g., REGION) if analysis expands to that
dat$ISLAND<-drop.levels(dat$ISLAND)
dat$SEC_NAME<-drop.levels(dat$SEC_NAME)
################################################
### Select which SPECIES/GROUP on which to focus:
#fish<-"INSTTotFishMinusSJRTB" # FULL DATASET - 730 sites
#fish<-"PRIMARY" # 4 zeroes
#fish<-"SECONDARY" # no zeroes
fish<-"PLANKTIVORE" # 41 zeroes
#fish<-"PISCIVORE" # 246 zeroes
######################################### Select response column
#indicator <- "Site-level Average Length"
indicator <- "Site-level Biomass"
focus <- paste("log",fish,sep="")
#focus <- paste("cuberoot_log",fish,sep="")
response <- paste("log (", fish, " biomass)", sep="")
########################################## Histograms
hist(dat[,fish],breaks=30,main=fish, xlab=indicator)
# No longer exploring zero-inflation model
#hist(dat[dat[,fish]>0, fish])
hist(log(dat[,fish]),breaks=20,main=response, xlab=indicator)
# Creates a more normal distribution
# No longer exploring zero-inflation model
#hist(log(dat[dat[,fish]>0,fish]))
hist(dat$HARD_CORAL,breaks=10, xlab="Hard Coral")
hist(dat$HUMANS20,breaks=10)
hist(log(dat$HUMANS20),breaks=10)
#hist(dat$HUMANS20^2,breaks=10)
#hist(log(dat$HUMANS20^2),breaks=10)
hist(dat$HUMANS200,breaks=10, xlab="Humans 200")
hist(log(dat$HUMANS200),breaks=10, xlab="Humans 200")
#dat$HUMANS200<-log(dat$HUMANS200)
##########################################TRANSFORMATIONS
# Log Fish: Could not get non-logged data to converge
### FIRST, FOR HERBIVORES ANALYSIS (i.e., fish<-"PRIMARY"), there are four sites with zeroes, remove these
### OTHERWISE they create NA terms (symbolized by "-Inf")
#dat<-dat[dat[,fish]>0,]
### FOR OTHER ANALYSES with more zero-inflation, replace zeroes with small number
dat[,fish][(dat[,fish]==0)]<-0.0001
hist(dat[,fish],breaks=30,main=fish, xlab=indicator)
sum(dat[,fish]==0)
min(dat[,fish])
dat <- cbind(dat, log(dat[,fish])) # No longer need + 1 since this isn't a zero-inflated model
names(dat)[grep("fish", names(dat))]<-paste("log",fish,sep="")
names(dat)
hist(dat[,(paste("log",fish,sep=""))],breaks=30,main=fish, xlab=indicator)
rm(list=ls())
library(reshape) # needed for melt()
library(rjags)
library(xtable)
library(coda)
library(gdata)    # needed for drop.levels()
library(car)      # needed for Variance Inflation Factor calculation
library(ggplot2)
library(corrplot)
##### CHANGE RESPONSE VARIABLE AS NEEDED: "PRIMARY" VS "INSTTotFishMinusSJRTB"
setwd("~/Analyses/fish-stock")
load("~/Analyses/fish-stock/input/TMPwsd_MHI_AllHerbivoresThru2016.RData") # by CONSUMER GROUPS
#load("~/Analyses/fish-stock/input/TMPwsd_REAthru2017-SpeciesLevel.RData") # by SPECIES
mhi<-wsd
#### GIVE "mhi" fish data to TOMOKO join with OCEANOGRAPHY data in ArcMAP
### FILES below are result of joining dat above with Jamie's latest oceanography data by averaging three nearest neighbors to fish sites
### For now, using Jamie's latest updated oceanography metrics (summarized thru 31 Dec 2014 - except waves which is Dec 2013)
chl.dat<-read.csv("~/Analyses/fish-stock/input/oceanInput/ChlA_fishDat_Join.csv")
irr.dat<-read.csv("~/Analyses/fish-stock/input/oceanInput/PAR_fishDat_Join.csv")
sst.dat<-read.csv("~/Analyses/fish-stock/input/oceanInput/SST_fishDat_Join.csv")
wav.dat<-read.csv("~/Analyses/fish-stock/input/oceanInput/Wave_fishDat_Join.csv")
chl.dat<-subset(chl.dat, select=-POINT_FREQUENCY)
irr.dat<-subset(irr.dat, select=-POINT_FREQUENCY)
sst.dat<-subset(sst.dat, select=-POINT_FREQUENCY)
wav.dat<-subset(wav.dat, select=-POINT_FREQUENCY)
# Merge all ocean dat together
ocean.common<-names(chl.dat)[1:75] #### NOTE: COLUMN NAMES ARE HARD-CODED; NEED TO REVISIT THIS IF NEW DATAFILES ARE EVER USED
ocean.dat<-merge(chl.dat, irr.dat, by=ocean.common, all=TRUE)
ocean.dat<-merge(ocean.dat, sst.dat, by=ocean.common, all=TRUE)
ocean.dat<-merge(ocean.dat, wav.dat, by=ocean.common, all=TRUE)
### All data including data from post-bleaching years
table(mhi$OBS_YEAR, mhi$REGION)
#MHI NWHI PRIAs SAMOA S.MARIAN N.MARIAN
#2007   0  117     0     0        0        0
#2008   0    0    96   112        0        0
#2009   0  181    29     0       82       95
#2010 184  118   179   241        0        0
#2011   0  141    30     0      219      135
#2012 163   91   231   223        0        0
#2013 287    0     0     0        0        0
#2014   0   89    45     0      210      148
#2015 294   96   291   338        0        0
#2016 256  182    30   185        0        0
#2017   0    0    81     0      172      159
table(ocean.dat$OBS_YEAR, ocean.dat$REGION)
#MHI
#2012 163
#2013 287
#2015 294
#2016 256
# i.e. REA data (mhi) and oceanography data (ocean.dat) have the same # of sites - merge should be perfect
### MERGE with fish data - simplify the merge by removing most common columns
ocean.dat<-subset(ocean.dat, select=-c(LATITUDE, LONGITUDE, DATE_, ANALYSIS_SEC, ANALYSIS_STRATA, ANALYSIS_YEAR, SEC_NAME,
METHOD, OBS_YEAR, REGION, REGION_NAME, ISLAND, REEF_ZONE, DEPTH_BIN, HABITAT_CODE,
DEPTH, HARD_CORAL, MA, CCA, SAND, OTHER_BENTHIC, MEAN_SH, SD_SH_DIFF, MAX_HEIGHT,
VISIBILITY, nCounts, nReps))
### All data including post-bleaching 2016 data
common<-c("SITEVISITID", "SITE")
alldat<-merge(mhi, ocean.dat, by=common)
### Only the study data - 2012 thru 2015
study.dat<-subset(alldat, OBS_YEAR<2016 & OBS_YEAR>2011)
# Join with Humans and Site Data
siteDat<-read.csv("~/Analyses/fish-stock/input/SITE MASTER2016.csv")
#W Again - simplify the merge by removing most common columns
#Slight differences in the object class for "DATE_" and number of decimal numbers for "LAT" and "LONG"
sub.dat<-subset(study.dat, select=-c(DATE_, LATITUDE, LONGITUDE, ANALYSIS_YEAR, SEC_NAME))
#common<-names(siteDat)[names(siteDat) %in% names(study.dat)]
common<-c("SITE", "SITEVISITID", "REGION", "ISLAND", "REEF_ZONE", "OBS_YEAR", "DEPTH_BIN")
dat<-merge(sub.dat, siteDat, by=common)
### MERGE with benthic image analysis data (CPCe and CNET)
# Read in benthic image analysis (CPCe and CNET)
benthic.cnet<-read.csv(file="~/Analyses/fish-stock/input/Kelvin MHI BenthicImageAnalysis_CNET.csv", header=TRUE)
benthic.cpce<-read.csv(file="~/Analyses/fish-stock/input/Kelvin MHI BenthicImageAnalysis_CPCE.csv", header=TRUE)
## Aggregate morphology columns in CPCE data
# Encrusting corals:
enc.cols<-benthic.cpce[,grep("_ENC", names(benthic.cpce))]
# Sum and create new column that is identical to the column in benthic.cnet
benthic.cpce$CORAL_Encrusting.hard.coral<-apply(enc.cols, MARGIN=1, FUN=sum)
# Massive corals:
mass.cols<-benthic.cpce[,grep("_MASS", names(benthic.cpce))]
# Sum and create new column that is identical to the column in benthic.cnet
benthic.cpce$CORAL_Massive.hard.coral<-apply(mass.cols, MARGIN=1, FUN=sum)
# Branching corals:
bran.cols<-benthic.cpce[,grep("_BR", names(benthic.cpce))]
# Sum and create new column that is identical to the column in benthic.cnet
benthic.cpce$CORAL_Branching.hard.coral<-apply(bran.cols, MARGIN=1, FUN=sum)
common.cats<-names(benthic.cnet)[names(benthic.cnet) %in% names(benthic.cpce)]
benthic.cnet.common<-subset(x=benthic.cnet, select=common.cats)
benthic.cpce.common<-subset(x=benthic.cpce, select=common.cats)
benthic<-rbind(benthic.cnet.common, benthic.cpce.common)
#Again, when merging, don't merge by date, latitude, or longitude.
common2<-names(benthic)[names(benthic) %in% names(dat)]
common<-common[!(common %in% c("DATE_", "LATITUDE", "LONGITUDE"))]
benthic<-subset(benthic, select=-c(DATE_, LATITUDE, LONGITUDE))
common2<-c("SITE", "REGION", "ISLAND", "REEF_ZONE", "OBS_YEAR", "DEPTH_BIN")
dat<-merge(dat, benthic, by=common2)
write.csv(dat, file="~/Analyses/fish-stock/RESULTS/allDat_2012-2015_JOIN.csv", quote=FALSE)
### DAT drops from 744 rows to 730 rows (which sites are missing??)
# Sites that drop out:
#mhi$SITE[!mhi$SITE %in% dat$SITE]
#[1] LAN-00202 MAI-00472 MAI-00470 MOL-00482 KAU-00253 OAH-00432 OAH-00485
#[8] OAH-00444 OAH-00421 OAH-00428 OAH-00404 OAH-00385 OAH-00391 NII-01338
# ALL HAVE MISSING BENTHIC IMAGE ANALYSIS DATA (COULD POTENTIALLY BRING IN VISUAL ESTIMATED DATA, BUT THIS WOULD BE INCONSISTENT - HAVE ENOUGH SITES, OK WITH DROPPING THESE)
## ADD HABITAT CATEGORY ID VARIABLES
# ADD ID VARIABLE FOR REEF vs NONREEF
#reef.hab<-(dat$HABITAT_CODE=="AGR" | dat$HABITAT_CODE=="APR" | dat$HABITAT_CODE=="APS")
reef.hab<-(dat$HABITAT_CODE=="AGR")
dat$REEF<-as.numeric(reef.hab)
# ADD ID VARIABLE FOR PAVEMENT vs NON-PAVEMENT
#pave.hab<-(dat$HABITAT_CODE=="PAV" | dat$HABITAT_CODE=="PPR" | dat$HABITAT_CODE=="PSC" | dat$HABITAT_CODE=="SCR" | dat$HABITAT_CODE=="RRB")
pave.hab<-(dat$HABITAT_CODE=="PAV")
dat$PAV<-as.numeric(pave.hab)
# ADD ID VARIABLE FOR ROB vs NONROB
rob.hab<-dat$HABITAT_CODE=="ROB"
dat$ROB<-as.numeric(rob.hab)
# ADD ID VARIABLE FOR APR vs NONAPR
apr.hab<-dat$HABITAT_CODE=="APR"
dat$APR<-as.numeric(apr.hab)
# ADD ID VARIABLE FOR APS vs NONAPS
aps.hab<-dat$HABITAT_CODE=="APS"
dat$APS<-as.numeric(aps.hab)
# ADD ID VARIABLE FOR MIX vs NONMIX
mix.hab<-dat$HABITAT_CODE=="MIX"
dat$MIX<-as.numeric(mix.hab)
# ADD ID VARIABLE FOR PPR vs PPR
ppr.hab<-dat$HABITAT_CODE=="PPR"
dat$PPR<-as.numeric(ppr.hab)
# ADD ID VARIABLE FOR PSC vs NONPSC
psc.hab<-dat$HABITAT_CODE=="PSC"
dat$PSC<-as.numeric(psc.hab)
# ADD ID VARIABLE FOR RRB vs NONRRB
rrb.hab<-dat$HABITAT_CODE=="RRB"
dat$RRB<-as.numeric(rrb.hab)
# ADD ID VARIABLE FOR SAG vs NONSAG
sag.hab<-dat$HABITAT_CODE=="SAG"
dat$SAG<-as.numeric(sag.hab)
# ADD ID VARIABLE FOR SCR vs NONSCR
scr.hab<-dat$HABITAT_CODE=="SCR"
dat$SCR<-as.numeric(scr.hab)
# WILL HAVE TO DROP LEVELS FOR OTHER hierarchical levels (e.g., REGION) if analysis expands to that
dat$ISLAND<-drop.levels(dat$ISLAND)
dat$SEC_NAME<-drop.levels(dat$SEC_NAME)
################################################
### Select which SPECIES/GROUP on which to focus:
#fish<-"INSTTotFishMinusSJRTB" # FULL DATASET - 730 sites
#fish<-"PRIMARY" # 4 zeroes
#fish<-"SECONDARY" # no zeroes
fish<-"PLANKTIVORE" # 41 zeroes
#fish<-"PISCIVORE" # 246 zeroes
######################################### Select response column
#indicator <- "Site-level Average Length"
indicator <- "Site-level Biomass"
focus <- paste("log",fish,sep="")
#focus <- paste("cuberoot_log",fish,sep="")
response <- paste("log (", fish, " biomass)", sep="")
########################################## Histograms
hist(dat[,fish],breaks=30,main=fish, xlab=indicator)
# No longer exploring zero-inflation model
#hist(dat[dat[,fish]>0, fish])
hist(log(dat[,fish]),breaks=20,main=response, xlab=indicator)
# Creates a more normal distribution
# No longer exploring zero-inflation model
#hist(log(dat[dat[,fish]>0,fish]))
hist(dat$HARD_CORAL,breaks=10, xlab="Hard Coral")
hist(dat$HUMANS20,breaks=10)
hist(log(dat$HUMANS20),breaks=10)
#hist(dat$HUMANS20^2,breaks=10)
#hist(log(dat$HUMANS20^2),breaks=10)
hist(dat$HUMANS200,breaks=10, xlab="Humans 200")
hist(log(dat$HUMANS200),breaks=10, xlab="Humans 200")
#dat$HUMANS200<-log(dat$HUMANS200)
##########################################TRANSFORMATIONS
# Log Fish: Could not get non-logged data to converge
### FIRST, FOR HERBIVORES ANALYSIS (i.e., fish<-"PRIMARY"), there are four sites with zeroes, remove these
### OTHERWISE they create NA terms (symbolized by "-Inf")
#dat<-dat[dat[,fish]>0,]
### FOR OTHER ANALYSES with more zero-inflation, replace zeroes with small number
dat[,fish][(dat[,fish]==0)]<-0.01
hist(dat[,fish],breaks=30,main=fish, xlab=indicator)
# now log
dat <- cbind(dat, log(dat[,fish])) # No longer need + 1 since this isn't a zero-inflated model
names(dat)[grep("fish", names(dat))]<-paste("log",fish,sep="")
hist(dat[,(paste("log",fish,sep=""))],breaks=30,main=fish, xlab=indicator)
